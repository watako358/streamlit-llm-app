from dotenv import load_dotenv

load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
import os
import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

# OpenAI APIã‚’åˆ©ç”¨ã™ã‚‹LLMã‚’åˆæœŸåŒ–
llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

# --- LLMå•ã„åˆã‚ã›é–¢æ•° ---
def get_llm_response(user_text: str, role: str) -> str:
    """å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã¨å½¹å‰²ã‚’åŸºã«LLMã¸å•ã„åˆã‚ã›ã€å›ç­”ã‚’è¿”ã™"""
    if role.startswith("C"):
        system_prompt = "ã‚ãªãŸã¯çµŒé¨“è±Šå¯ŒãªåŒ»è€…ã§ã™ã€‚"
    elif role.startswith("D"):
        system_prompt = "ã‚ãªãŸã¯å„ªç§€ãªæŠ•è³‡ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚"
    else:
        system_prompt = "ã‚ãªãŸã¯åšè­˜ãªå°‚é–€å®¶ã§ã™ã€‚"

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_text),
    ]

    result = llm(messages)
    return result.content

# --- Streamlit UI ---
st.title("ğŸ’¬ LangChain + Streamlit Demo")

# ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸æŠ
role = st.radio(
    "å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸ã‚“ã§ãã ã•ã„:",
    ("C: åŒ»è€…", "D: æŠ•è³‡ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼")
)

# å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
user_input = st.text_area("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:")

# é€ä¿¡ãƒœã‚¿ãƒ³
if st.button("é€ä¿¡"):
    if user_input.strip() == "":
        st.warning("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­..."):
            response = get_llm_response(user_input, role)
        st.subheader("å›ç­”:")
        st.write(response)