import os
import streamlit as st
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

# .env ã®èª­ã¿è¾¼ã¿ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œç”¨ï¼‰
load_dotenv()

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ã‚­ãƒ¼ã‚’å–å¾—
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# LLM åˆæœŸåŒ–
llm = ChatOpenAI(
    model_name="gpt-4o-mini",
    temperature=0,
    openai_api_key=OPENAI_API_KEY
)

# --- LLMå•ã„åˆã‚ã›é–¢æ•° ---
def get_llm_response(user_text: str, role: str) -> str:
    if role.startswith("A"):
        system_prompt = "ã‚ãªãŸã¯çµŒé¨“è±Šå¯ŒãªåŒ»è€…ã§ã™ã€‚"
    elif role.startswith("B"):
        system_prompt = "ã‚ãªãŸã¯å„ªç§€ãªæŠ•è³‡ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚"

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_text),
    ]

    result = llm(messages)
    return result.content

# --- Streamlit UI ---
st.title("ğŸ’¬ LangChain + Streamlit Demo")

role = st.radio(
    "å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸ã‚“ã§ãã ã•ã„:",
    ("A: åŒ»è€…", "B: æŠ•è³‡ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼")
)

user_input = st.text_area("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:")

if st.button("é€ä¿¡"):
    if user_input.strip() == "":
        st.warning("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­..."):
            response = get_llm_response(user_input, role)
        st.subheader("å›ç­”:")
        st.write(response)