import os
import streamlit as st
from dotenv import load_dotenv

# LangChain æœ€æ–°ä»•æ§˜
from langchain.chat_models import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

# --- ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ ---
load_dotenv()  # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç›´ä¸‹ã® .env ã‚’èª­ã¿è¾¼ã‚€
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# --- LLM åˆæœŸåŒ– ---
llm = ChatOpenAI(
    model_name="gpt-4o-mini",
    temperature=0,
    openai_api_key=OPENAI_API_KEY
)

# --- LLMå•ã„åˆã‚ã›é–¢æ•° ---
def get_llm_response(user_text: str, role: str) -> str:
    """å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã¨å½¹å‰²ã‚’åŸºã«LLMã¸å•ã„åˆã‚ã›ã€å›ç­”ã‚’è¿”ã™"""
    if role.startswith("A"):
        system_prompt = "ã‚ãªãŸã¯çµŒé¨“è±Šå¯ŒãªåŒ»è€…ã§ã™ã€‚"
    elif role.startswith("B"):
        system_prompt = "ã‚ãªãŸã¯å„ªç§€ãªæŠ•è³‡ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚"

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_text),
    ]

    result = llm(messages)
    return result.content

# --- Streamlit UI ---
st.title("ğŸ’¬ LangChain + Streamlit Demo")

role = st.radio(
    "å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸ã‚“ã§ãã ã•ã„:",
    ("A: åŒ»è€…", "B: æŠ•è³‡ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼")
)

user_input = st.text_area("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:")

if st.button("é€ä¿¡"):
    if user_input.strip() == "":
        st.warning("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­..."):
            response = get_llm_response(user_input, role)
        st.subheader("å›ç­”:")
        st.write(response)